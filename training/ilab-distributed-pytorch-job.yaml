apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: ilab-distributed-training-test
  namespace: ikolchin
spec:
  pytorchReplicaSpecs:
    Master:
      replicas: 1
      restartPolicy: Never
      template:
        metadata:
          annotations:
            sidecar.istio.io/inject: 'false'
        spec:
          containers:
            - command: ["python3.11", "training/src/instructlab/training/main_ds.py"]
              args:
                  ["--model_name_or_path", "ibm-granite/granite-7b-base",
                   "--data_path", "training/sample-data/train_all_pruned_SDG.jsonl",
                   "--output_dir", "training/sample-data",
                   "--num_epochs", "2",
                    "--effective_batch_size", "3840",
                    "--learning_rate", "0.000002",
                    "--num_warmup_steps", "800",
                    "--save_samples", "0",
                    "--log_level", "INFO",
                    "--max_batch_len", "20000",
                    "--seed", "42",
                    "--chat-tmpl-path", "training/src/instructlab/training/chat_templates/ibm_generic_tmpl.py",
                    "--checkpoint_at_epoch",
                    "--is_granite",
                    "--cpu_offload_optimizer",
                    "--cpu_offload_optimizer_ratio", "1",
                    "--mock_data"
                  ]
              image: 'quay.io/michaelclifford/test-train:0.0.12'
              name: pytorch
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  nvidia.com/gpu: 1
              env:
                - name: WORLD_SIZE
                  value: "2"
                - name: NODE_RANK
                  value: "0" # For the master node
                - name: LOCAL_RANK
                  value: "0" # A hack due to the way PyTorchJob works
                - name: RANK
                  value: $(NODE_RANK)
                - name: GROUP_RANK
                  value: $(NODE_RANK)
    Worker:
      replicas: 1
      restartPolicy: Never
      template:
        metadata:
          annotations:
            sidecar.istio.io/inject: 'false'
        spec:
          containers:
            - command: ["python3.11", "training/src/instructlab/training/main_ds.py"]
              args:
                  ["--model_name_or_path", "ibm-granite/granite-7b-base",
                   "--data_path", "training/sample-data/train_all_pruned_SDG.jsonl",
                   "--output_dir", "training/sample-data",
                   "--num_epochs", "2",
                    "--effective_batch_size", "3840",
                    "--learning_rate", "0.000002",
                    "--num_warmup_steps", "800",
                    "--save_samples", "0",
                    "--log_level", "INFO",
                    "--max_batch_len", "20000",
                    "--seed", "42",
                    "--chat-tmpl-path", "training/src/instructlab/training/chat_templates/ibm_generic_tmpl.py",
                    "--checkpoint_at_epoch",
                    "--is_granite",
                    "--cpu_offload_optimizer",
                    "--cpu_offload_optimizer_ratio", "1",
                    "--mock_data"
                  ]
              image: 'quay.io/michaelclifford/test-train:0.0.12'
              name: pytorch
              resources:
                limits:
                  nvidia.com/gpu: 1
                requests:
                  nvidia.com/gpu: 1
              env:
                - name: WORLD_SIZE
                  value: "2"
                - name: NODE_RANK
                  value: "1" # For the worker node
                - name: LOCAL_RANK
                  value: "0" # A hack due to the way PyTorchJob works
                - name: RANK
                  value: $(NODE_RANK)
                - name: GROUP_RANK
                  value: $(NODE_RANK)
  runPolicy:
    suspend: false
